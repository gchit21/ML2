**IEEE-CIS fraud detection**
	კონკურსის მოკლე მიმოხილვა: კონკურსის მთავარი მიზანია დავატრეინინგოთ მოდელი, რომელსაც შეეძლება გარჩევა, თუ რომელი გაკეთებული
        ტრანზაქცია არის fraud-ი. გადმოგვეცემა 2 ტიპის Dataset-ი, ერთში მოცემულია ტრანზაქციები,ხოლო მეორეში იდენტიფიკატორები,შედეგად 
	ჯმში გვაქვს თითქმის 500 ათასი მონაცემი (row) და 430-მდე ინფორმაციის სვეტი, რომელთაგან ნაწილი კატეგორიული ცვლადია და საჭიროებსა 
	იცხვითში გადაყვანას. ამათ გარდა მოცემული სვეტები დამაპულია, რაც იმას ნიშნავს, რომ არ გვაქვს ინფორმაცია,თუ რას წარმოაგდენენ სვეტები
	და რანაირი დამოკიდებულება/გავლენა აქვთ target-თან. ჩვენი Target-ია isFraud-სვეტი.

**რეპოზიტორიის სტრუქტურა:**
	რეპოზიტორია შეიცავს 3 ფაილს: README ფაილი(ამ წამს კითხულობ ამას), model_experiment_XGBoost.ipynb - პითონის ფაილი, სადაც არის Data set-ის
            cleaning, engineering,correlation filtering,scaling, feature selection და XGBoost მოდელის გაზრთა pipeline-ის გამოყენებით და mlflow-თი დალოგვა.
	model_inference.ipynb - სადაც ხდება ჩემი საუკეთესო მოდელის mlflow-დან ჩამოწერა და kaggle "IEEE-CIS Fraud Detection" competition-ის Test-ზე 
	submission-ის დაგენერირება.  
	
    
**Feature Engineering: **
	პირველ რიგში გადავაგდე ისეთი სვეტები, რომელთა na-ს წილი მეტია გარკვეულ threshold-ზე, ამ threshold-ს ვცვლიდი და ვაკვირდებოდი მეტრიკების ცვლილებებს.
	შემდეგ იმის გამო რომ non-fraud-ის რაოდენობა გაცილებით აღემატება fraud-ისას ვქენი undersampling-ი. ამის მერე კი მივხედე დარჩენილი სვეტების შევსებას, 
	კერძოდ შევავსე  რიცხვითი სვეტები მედიანით, ხოლო კატეგორიულებში უბრალოდ "NotAv" ჩავუწერე.შემდეგ გამოვიყენე sklearn-ის WoeEncoder-რათა გადამეყვანა 
	კატეგორიული ცვლადები რიცხვითში და მერე კორელაციის მიხედვით მაღალკორებული სვეტები გადავაგდე. 		
	
**Feature Selection:**
    	feature selection-ისთვის გამოვიყენე custom feature selector,რომელშიც განკუთვნილია XGBoost-ისთვის. იდეაში 2 ფაზიანი RFE არის, რომლის პირველ ფაზაში ვაგდებ ისეთ სვეტებს,
	რომელთაც გავლენა არ აქვთ target-ზე, ხოლო მეორე ფაზის დროს უკვე ფრთხილად ვარჩევ feature-ებს.

**Training:**
	რადგან  ეს Competition ფაქტობრივად კლასიფიკაციის ამოცანაა, პირდაპირ ავირჩიე XGBoost-ის მოდელის გაწვრთნა, რადგან ასეთ შემთხვევებში ძალიან კარგია.
	რაც შეეხება მოდელის პარამეტრებს ექსპერიმენტულად ვარჩევდი, ავარჩიე  პარამეტრების მნიშვნელობები რანდომულად  და იმის  მიხედვით როგორ შეიცვლებოდა
	train test-ის  f1-ები ვაკორექტირებდი პარამეტრებს, რათა როგორმე გამოვსულიყავი overfit-იდან, თუმცა არ გამოვიდა. პირველი ტესტზე მივიღე, რომ f1 train/test
	იყო 0.75/0.65-ზე რაც მთლად კარგი შედეგი არაა,რადგან 0.1-იანი სხვაობაა და აშკარა overfit-ია. ამ სხვაობის 0.05-მდე დაყვანა შევძელი, თუმცა თავად f1-ი გაუარესდა.

**MLflow Tracking:**
	MLflow ექსპერიმენტების ბმული: 
https://dagshub.com/gchit21/ML2.mlflow/#/experiments/1?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D
	ჩაწერილი მეტრიკები: precision,recall,f1,auc
	საუკეთესო მოდელის მეტრიკები: precision:0.67 , recall:0.51, f1:0.58, auc:0.936 (მაინც overfit-ში დარჩა)
								   